{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Some-conversion-between-you-and-your-engineer-friend...\" data-toc-modified-id=\"Some-conversion-between-you-and-your-engineer-friend...-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Some conversion between you and your engineer friend...</a></span></li><li><span><a href=\"#Your-friend-diligently-removed-labels\" data-toc-modified-id=\"Your-friend-diligently-removed-labels-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Your friend diligently removed labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Iris-data\" data-toc-modified-id=\"Load-Iris-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris?ref=datanews.io\" target=\"_blank\">Iris</a> data</a></span></li><li><span><a href=\"#Check-missing-values\" data-toc-modified-id=\"Check-missing-values-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Check missing values</a></span></li><li><span><a href=\"#Get-the-features-and-target\" data-toc-modified-id=\"Get-the-features-and-target-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Get the features and target</a></span></li><li><span><a href=\"#Check-categorical-features\" data-toc-modified-id=\"Check-categorical-features-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Check categorical features</a></span></li><li><span><a href=\"#Check-categorical-target\" data-toc-modified-id=\"Check-categorical-target-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Check categorical target</a></span></li><li><span><a href=\"#Encode-the-target\" data-toc-modified-id=\"Encode-the-target-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Encode the target</a></span></li><li><span><a href=\"#Divide-the-data-into-training-and-testing\" data-toc-modified-id=\"Divide-the-data-into-training-and-testing-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Divide the data into training and testing</a></span></li><li><span><a href=\"#Standardize-the-features\" data-toc-modified-id=\"Standardize-the-features-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Standardize the features</a></span></li><li><span><a href=\"#Get-the-index-of-rows-containing-the-three-unique-class-labels\" data-toc-modified-id=\"Get-the-index-of-rows-containing-the-three-unique-class-labels-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Get the index of rows containing the three unique class labels</a></span></li><li><span><a href=\"#Remove-the-classes-(by-chaining-them-to--1)-in-rows-where-the-classes-have-already-appeared\" data-toc-modified-id=\"Remove-the-classes-(by-chaining-them-to--1)-in-rows-where-the-classes-have-already-appeared-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>Remove the classes (by chaining them to -1) in rows where the classes have already appeared</a></span></li></ul></li><li><span><a href=\"#Step-2:-Your-turn\" data-toc-modified-id=\"Step-2:-Your-turn-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Step 2: Your turn</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-KMeans-model\" data-toc-modified-id=\"The-KMeans-model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>The KMeans model</a></span></li><li><span><a href=\"#On-the-training-data,-compute-cluster-centers-and-predict-cluster-indices\" data-toc-modified-id=\"On-the-training-data,-compute-cluster-centers-and-predict-cluster-indices-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>On the training data, compute cluster centers and predict cluster indices</a></span></li><li><span><a href=\"#Create-the-map-from-cluster-index-to-class-label-(that-is-not--1)\" data-toc-modified-id=\"Create-the-map-from-cluster-index-to-class-label-(that-is-not--1)-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Create the map from cluster index to class label (that is not -1)</a></span></li><li><span><a href=\"#On-the-testing-data,-predict-cluster-indices\" data-toc-modified-id=\"On-the-testing-data,-predict-cluster-indices-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>On the testing data, predict cluster indices</a></span></li><li><span><a href=\"#On-the-testing-data,-transform-the-cluster-indices-into-class-labels\" data-toc-modified-id=\"On-the-testing-data,-transform-the-cluster-indices-into-class-labels-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>On the testing data, transform the cluster indices into class labels</a></span></li><li><span><a href=\"#Print-the-accuracy\" data-toc-modified-id=\"Print-the-accuracy-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Print the accuracy</a></span></li></ul></li><li><span><a href=\"#Step-3:-You-go-beyond-(to-improve-the-prediction-accuracy)\" data-toc-modified-id=\"Step-3:-You-go-beyond-(to-improve-the-prediction-accuracy)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Step 3: You go beyond (to improve the prediction accuracy)</a></span><ul class=\"toc-item\"><li><span><a href=\"#On-the-training-data,-transform-the-cluster-indices-into-class-labels\" data-toc-modified-id=\"On-the-training-data,-transform-the-cluster-indices-into-class-labels-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>On the training data, transform the cluster indices into class labels</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning-and-model-selection\" data-toc-modified-id=\"Hyperparameter-tuning-and-model-selection-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Hyperparameter tuning and model selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-the-dictionary-of-classifiers\" data-toc-modified-id=\"Create-the-dictionary-of-classifiers-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Create the dictionary of classifiers</a></span></li><li><span><a href=\"#Create-the-dictionary-of-pipeline\" data-toc-modified-id=\"Create-the-dictionary-of-pipeline-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Create the dictionary of pipeline</a></span></li><li><span><a href=\"#Create-the-dictionary-of-parameter-grids\" data-toc-modified-id=\"Create-the-dictionary-of-parameter-grids-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Create the dictionary of parameter grids</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-parameter-grid-for-logistic-regression\" data-toc-modified-id=\"The-parameter-grid-for-logistic-regression-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>The parameter grid for logistic regression</a></span></li><li><span><a href=\"#The-parameter-grid-for-MLP\" data-toc-modified-id=\"The-parameter-grid-for-MLP-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>The parameter grid for MLP</a></span></li><li><span><a href=\"#The-parameter-grid-for-decision-tree\" data-toc-modified-id=\"The-parameter-grid-for-decision-tree-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>The parameter grid for decision tree</a></span></li><li><span><a href=\"#The-parameter-grid-for-random-forest\" data-toc-modified-id=\"The-parameter-grid-for-random-forest-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>The parameter grid for random forest</a></span></li><li><span><a href=\"#The-parameter-grid-for-SVC\" data-toc-modified-id=\"The-parameter-grid-for-SVC-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>The parameter grid for SVC</a></span></li><li><span><a href=\"#The-parameter-grid-for-KNN\" data-toc-modified-id=\"The-parameter-grid-for-KNN-6.3.6\"><span class=\"toc-item-num\">6.3.6&nbsp;&nbsp;</span>The parameter grid for KNN</a></span></li><li><span><a href=\"#The-parameter-grid-for-GNB\" data-toc-modified-id=\"The-parameter-grid-for-GNB-6.3.7\"><span class=\"toc-item-num\">6.3.7&nbsp;&nbsp;</span>The parameter grid for GNB</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Hyperparameter tuning</a></span></li><li><span><a href=\"#Model-selection\" data-toc-modified-id=\"Model-selection-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Model selection</a></span></li><li><span><a href=\"#Get-the-accuracy-of-the-best-model-on-the-testing-data\" data-toc-modified-id=\"Get-the-accuracy-of-the-best-model-on-the-testing-data-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Get the accuracy of the best model on the testing data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Machine Learning I (DATS 6202 - O10), Spring 2019\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Exercise 8 (Solution)\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Author: Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Complete the missing parts indicated by # Implement me\n",
    "- Particularly, the code should\n",
    "    - be bug-free (while the output produced by your solution being the same as the provided output does not necessarily mean your code is bug-free, it is very likely that there is a bug in your code when the two kinds of output are different)\n",
    "    - be commented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some conversion between you and your engineer friend...\n",
    "$\\textbf{Friend}$: Thanks again for solving the XOR problem only using perceptrons! You are really awesome!\n",
    "\n",
    "$\\textbf{You}$: I know.\n",
    "\n",
    "$\\textbf{Friend}$: ... Have you ever worked on Iris?\n",
    "\n",
    "$\\textbf{You}$: Who hasn't?\n",
    "\n",
    "$\\textbf{Friend}$: ... I heard that missing values can cause a lot of troubles.\n",
    "\n",
    "$\\textbf{You}$: Not necessarily. You can still do things with them.\n",
    "\n",
    "$\\textbf{Friend}$: Oh really? What if 90% of the class labels are missing? Can you predict them?\n",
    "\n",
    "$\\textbf{You}$: No.\n",
    "\n",
    "$\\textbf{Friend}$: Well, you know what? Don't feel bad about yourself. You don't have to know everything.\n",
    "\n",
    "$\\textbf{You}$: What I am saying is, I do not even need 10% labels. Remove all the labels if you want and leave only three unique ones. I can give you over 70% prediction accuracy.\n",
    "\n",
    "$\\textbf{Friend}$: Only three labels? Are you serious?\n",
    "\n",
    "$\\textbf{You}$: Positive. The only problem is, I am a data scientist. I do not create missing values on purpose. You do that. Then I will go from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your friend diligently removed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load [Iris](http://archive.ics.uci.edu/ml/datasets/Iris?ref=datanews.io) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width       target\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                 header=None)\n",
    "\n",
    "# Specify the name of the columns\n",
    "df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'target']\n",
    "\n",
    "# Specify the name of the target\n",
    "target = 'target'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length    0\n",
       "sepal width     0\n",
       "petal length    0\n",
       "petal width     0\n",
       "target          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace ? with np.NaN\n",
    "df = df.replace('?', np.NaN)\n",
    "\n",
    "# Check NA\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length:\n",
      "5.0    10\n",
      "6.3     9\n",
      "5.1     9\n",
      "6.7     8\n",
      "5.7     8\n",
      "5.5     7\n",
      "5.8     7\n",
      "6.4     7\n",
      "6.0     6\n",
      "4.9     6\n",
      "6.1     6\n",
      "5.4     6\n",
      "5.6     6\n",
      "6.5     5\n",
      "4.8     5\n",
      "7.7     4\n",
      "6.9     4\n",
      "5.2     4\n",
      "6.2     4\n",
      "4.6     4\n",
      "7.2     3\n",
      "6.8     3\n",
      "4.4     3\n",
      "5.9     3\n",
      "6.6     2\n",
      "4.7     2\n",
      "7.6     1\n",
      "7.4     1\n",
      "4.3     1\n",
      "7.9     1\n",
      "7.3     1\n",
      "7.0     1\n",
      "4.5     1\n",
      "5.3     1\n",
      "7.1     1\n",
      "Name: sepal length, dtype: int64\n",
      "\n",
      "sepal width:\n",
      "3.0    26\n",
      "2.8    14\n",
      "3.2    13\n",
      "3.4    12\n",
      "3.1    12\n",
      "2.9    10\n",
      "2.7     9\n",
      "2.5     8\n",
      "3.5     6\n",
      "3.8     6\n",
      "3.3     6\n",
      "2.6     5\n",
      "2.3     4\n",
      "3.6     3\n",
      "2.4     3\n",
      "2.2     3\n",
      "3.7     3\n",
      "3.9     2\n",
      "4.2     1\n",
      "4.1     1\n",
      "4.4     1\n",
      "2.0     1\n",
      "4.0     1\n",
      "Name: sepal width, dtype: int64\n",
      "\n",
      "petal length:\n",
      "1.5    14\n",
      "1.4    12\n",
      "5.1     8\n",
      "4.5     8\n",
      "1.3     7\n",
      "1.6     7\n",
      "5.6     6\n",
      "4.0     5\n",
      "4.9     5\n",
      "4.7     5\n",
      "4.8     4\n",
      "1.7     4\n",
      "4.4     4\n",
      "4.2     4\n",
      "5.0     4\n",
      "4.1     3\n",
      "5.5     3\n",
      "4.6     3\n",
      "6.1     3\n",
      "5.7     3\n",
      "3.9     3\n",
      "5.8     3\n",
      "1.2     2\n",
      "1.9     2\n",
      "6.7     2\n",
      "3.5     2\n",
      "5.9     2\n",
      "6.0     2\n",
      "5.4     2\n",
      "5.3     2\n",
      "3.3     2\n",
      "4.3     2\n",
      "5.2     2\n",
      "6.3     1\n",
      "1.1     1\n",
      "6.4     1\n",
      "3.6     1\n",
      "3.7     1\n",
      "3.0     1\n",
      "3.8     1\n",
      "6.6     1\n",
      "6.9     1\n",
      "1.0     1\n",
      "Name: petal length, dtype: int64\n",
      "\n",
      "petal width:\n",
      "0.2    28\n",
      "1.3    13\n",
      "1.5    12\n",
      "1.8    12\n",
      "1.4     8\n",
      "2.3     8\n",
      "1.0     7\n",
      "0.3     7\n",
      "0.4     7\n",
      "0.1     6\n",
      "2.0     6\n",
      "2.1     6\n",
      "1.2     5\n",
      "1.9     5\n",
      "1.6     4\n",
      "2.5     3\n",
      "2.2     3\n",
      "2.4     3\n",
      "1.1     3\n",
      "1.7     2\n",
      "0.6     1\n",
      "0.5     1\n",
      "Name: petal width, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the unique value and their number for each feature\n",
    "for j in range(X.shape[1]):\n",
    "    print(X.columns[j] + ':')\n",
    "    print(X.iloc[:, j].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check categorical target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Iris-versicolor    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the unique value and their number for the target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "pd.DataFrame(data=y, columns=[target])[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train before removing the class labels:\n",
      "[2 2 2 0 0 0 1 2 1 2 0 1 1 1 0 0 2 1 1 2 2 1 0 0 1 1 0 1 2 2 2 1 2 2 0 0 0\n",
      " 1 0 0 2 1 2 0 0 0 1 1 0 1 1 1 2 0 1 1 1 1 2 0 1 2 1 1 2 1 2 0 1 2 2 2 2 0\n",
      " 2 0 0 2 1 0 0 0 0 0 1 2 2 2 0 2 0 0 1 1 1 1 0 2 2 0 2 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Print y_train\n",
    "print('y_train before removing the class labels:')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the index of rows containing the three unique class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes, indices = np.unique(y_train, return_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the classes (by chaining them to -1) in rows where the classes have already appeared\n",
    "- In the end, y_train contains only three unique class labels. The removed classes are denoted by '-1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train after removing the labels:\n",
      "[ 2 -1 -1  0 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([y_train[i] if i in indices else -1 for i in range(y_train.shape[0])])\n",
    "\n",
    "# Print y_train\n",
    "print('y_train after removing the labels:')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Your turn\n",
    "Hint: You are expected to use KMeans to handle this problem. The idea is as follows:\n",
    "1. When applying KMeans on the training data, we get the cluster index for each sample (in the training data), some of which have class labels (that are not -1). Thus we can obtain a map (a dictionary in essence) from cluster index to class.\n",
    "2. When applying KMeans on the testing data, we get the cluster index for each sample (in the testing data). Using the map above, we can obtain the predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The KMeans model\n",
    "Hint: Consider the number of class labels (in the data) when deciding the value of n_clusters for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Implement me\n",
    "km = KMeans(n_clusters=3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the training data, compute cluster centers and predict cluster indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = km.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the map from cluster index to class label (that is not -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "dict_ = {}\n",
    "for i in range(y_train.shape[0]):\n",
    "    if y_train[i] != -1:\n",
    "        key = y_train_pred[i]\n",
    "        val = y_train[i]\n",
    "        dict_[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the testing data, predict cluster indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = km.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the testing data, transform the cluster indices into class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "y_test_pred = np.array([dict_[y_test_pred[i]] for i in range(y_test_pred.shape[0])])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print('Accuracy:', end=' ')\n",
    "print(precision_recall_fscore_support(y_test_pred, y_test, average='micro')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: You go beyond (to improve the prediction accuracy)\n",
    "Hint:\n",
    "1. You may consider to do the same thing for y_train_pred (obtained in step 2.2), as what you did for y_test_pred (in step 2.5).\n",
    "2. In turn, every sample in y_train_pred has a predicted class label.\n",
    "3. As a result, you can first fit a classifier from X_train and y_train_pred, then use the model to predict the class label for X_test. The choice for the classifiers and their hyperparameter settings are up to you.\n",
    "4. You may consider to tweak the solution for Exercise_7 to handle this problem. However, as we discussed previously, please do not forget to cite the source of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the training data, transform the cluster indices into class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement me\n",
    "y_train_pred = np.array([dict_[y_train_pred[i]] for i in range(y_train_pred.shape[0])])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and model selection\n",
    "In this section\n",
    "- we first use the combination of Pipeline and GridSearchCV to fine tune the hyperparameters of 7 classifiers\n",
    "- we then select the best model across the 7 classifiers.\n",
    "\n",
    "Reference: most of the code in this section is from Exercise_7_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of classifiers\n",
    "In the dictionary:\n",
    "- the key is the acronym of the classifier\n",
    "- the value is the classifier (with random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mlp': MLPClassifier(random_state=0),\n",
    "        'dt': DecisionTreeClassifier(random_state=0),\n",
    "        'rf': RandomForestClassifier(random_state=0),\n",
    "        'svc': SVC(random_state=0),\n",
    "        'knn': KNeighborsClassifier(),\n",
    "        'gnb': GaussianNB()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of pipeline\n",
    "In the dictionary:\n",
    "- the key is the acronym of the classifier\n",
    "- the value is the pipeline (with StandardScaler and the classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    # Implement me\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of parameter grids\n",
    "In the dictionary:\n",
    "- the key is the acronym of the classifier\n",
    "- the value is the parameter grid of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for logistic regression\n",
    "The hyperparameters we want to fine tune are:\n",
    "- multi_class\n",
    "- solver\n",
    "- C\n",
    "\n",
    "Here we need to use two dictionaries in the parameter grid since 'multinomial' (multi_class) does not support 'liblinear' (solver). See details of the meaning of the hyperparametes in [sklearn logistic regression documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              \n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['lr'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for MLP\n",
    "The hyperparameters we want to fine tune are:\n",
    "- hidden_layer_sizes\n",
    "- activation\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn multi-layer perceptron documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__hidden_layer_sizes': [10, 100, 200],\n",
    "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['mlp'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for decision tree\n",
    "The hyperparameters we want to fine tune are:\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn decision tree documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['dt'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for random forest\n",
    "The hyperparameters we want to fine tune are:\n",
    "- n_estimators\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn random forest documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__n_estimators': [2, 10, 30],\n",
    "               'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['rf'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for SVC\n",
    "The hyperparameters we want to fine tune are:\n",
    "- C\n",
    "- gamma\n",
    "- kernel\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn SVC documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "               'clf__gamma': ['auto', 'scale'],\n",
    "               'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['svc'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for KNN\n",
    "The hyperparameters we want to fine tune are:\n",
    "- n_neighbors\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn KNN documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__n_neighbors': list(range(1, 11))}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['knn'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for GNB\n",
    "The hyperparameters we want to fine tune are:\n",
    "- var_smoothing\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn GNB documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'clf__var_smoothing': [10 ** i for i in range(-10, -7)]}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['gnb'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Here we use two functions for hyperparameter tuning:\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html): Exhaustive search over specified parameter values for an estimator\n",
    "- [StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html): Stratified K-Folds cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# For each classifier\n",
    "for name in pipe_clfs.keys():\n",
    "    # GridSearchCV\n",
    "    # Implement me\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      cv=StratifiedKFold(n_splits=10,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=0))\n",
    "    # Fit the pipeline\n",
    "    # Implement me\n",
    "    gs = gs.fit(X_train, y_train_pred)\n",
    "    \n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9904761904761905, {'clf__C': 1, 'clf__gamma': 'auto', 'clf__kernel': 'linear'}, <class 'sklearn.svm.classes.SVC'>]\n",
      "\n",
      "[0.9809523809523809, {'clf__C': 10, 'clf__multi_class': 'multinomial', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.9809523809523809, {'clf__activation': 'identity', 'clf__hidden_layer_sizes': 200}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.9809523809523809, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.9809523809523809, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.9809523809523809, {'clf__n_neighbors': 7}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.9714285714285714, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort best_score_param_estimators in descending order of the best_score_\n",
    "# Implement me\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the accuracy of the best model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', end=' ')\n",
    "# Implement me\n",
    "print(best_score_param_estimators[0][2].score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
